This is the Detailed Master Execution Plan. It is designed to be handed directly to a developer or an AI coding agent. It merges the Feature Requirements with the Token-Efficiency Architecture so that you build a high-performance, low-cost app from the start.

üì¶ Prerequisites (Library Stack)

Ensure these specific libraries are installed before starting.

code
Bash
download
content_copy
expand_less
# Core & UI
npx expo install expo-sqlite expo-linear-gradient expo-haptics
npm install @gorhom/bottom-sheet react-native-reanimated react-native-gesture-handler

# Audio & Media
npx expo install expo-av expo-speech expo-file-system expo-sharing

# Visualization & Utils
npm install react-native-gifted-charts date-fns
üõ† Phase 0: The "Efficient Brain" (Backend & DB)

Goal: Set up the infrastructure to handle data locally (free) and optimize AI calls (cheap).

1. Initialize SQLite (Local "Second Brain")

Action: Create a database utility file (db.ts). Initialize 3 tables:

api_cache: Stores AI responses.

Schema: hash_key (TEXT PK), response_json (TEXT), timestamp (INT)

user_stats: Tracks activity for the Dashboard.

Schema: id (INT PK), date (TEXT), type (TEXT: 'prediction'|'chat'), score (INT)

phrases: Stores SRS cards.

Schema: id (INT PK), original (TEXT), translated (TEXT), next_review (INT), ease_factor (FLOAT), interval (INT)

2. Refactor Backend Prompts (Token Minimization)

Action: Rewrite server.js prompt logic.

Logic: Remove conversational text. Use "One-Shot" JSON examples.

Old Prompt: "Please act as a Spanish tutor. Analyze the text..." (Expensive)

New Prompt:

code
Text
download
content_copy
expand_less
Role: ES Tutor. Level: {userLevel}.
Task: Predict next 3 words & check for cultural warnings.
Input: "{text}"
Output Format (JSON Only):
[{"word": "hola", "conf": 0.9, "type": "greeting", "cult_warn": null}]

Constraint: Set API max_completion_tokens: 100 and stop: ["]", "}"].

3. Standardize Difficulty (CEFR)

Action: Replace 1-10 slider logic.

Logic: Map UI selection to prompt variables:

Beginner -> Prompt: "Use A1 vocabulary (top 500 words)."

Advanced -> Prompt: "Use C1 vocabulary (idioms, complex grammar)."

üì± Phase 1: The "Smart" Predictor (UI & Logic)

Goal: Implement the main typing interface with "Zero-Waste" triggers.

4. The "Trigger" Engine (Logic)

Action: Replace debounce(500ms) in the text input handler.

New Logic: Only trigger fetchPrediction() if:

User types a Space (End of word).

User types Punctuation (., ?, !).

User pauses for > 1.5 seconds.

Local Optimization: If user is typing inside a word (e.g., "Hel_"), do not call AI.

5. Caching Layer (Logic)

Action: Wrap the API call in a checkCache function.

Logic:

Generate Hash: MD5(userInput + language + tone).

Check SQLite api_cache.

If Hit: Return JSON from DB (0ms latency, $0 cost).

If Miss: Call API -> Save to DB -> Return JSON.

6. Ghost Text & Chips (UI)

Ghost Text: Place a <Text> component absolutely positioned behind the <TextInput>.

Style: Color #ccc. It should display the top prediction right after the cursor.

Interaction: "Tab" or Swipe Right fills the input with the Ghost Text.

Confidence Chips: Render the prediction chips.

Style: Green Border if conf > 0.8. Yellow Border if conf < 0.8.

Interaction: Long Press opens @gorhom/bottom-sheet to show grammar details (if available).

üß† Phase 2: Retention System (SRS & Corrections)

Goal: Move from "Predicting" to "Learning" without draining tokens.

7. Spaced Repetition System (Logic)

Action: Implement the SM-2 Algorithm in a JS function.

Logic:

User rates a phrase: "Easy", "Good", "Hard".

Easy: Interval * 2.5. Hard: Interval = 1 day.

Update phrases table with new next_review timestamp.

UI: In "Explore Tab", query SQLite: SELECT * FROM phrases WHERE next_review <= Date.now().

8. On-Demand Correction (Logic)

Action: Add a specific "Check Grammar" button.

Efficiency: Do not run this automatically.

Process:

User clicks button.

Send prompt: Task: Correct grammar only. Input: "{text}". Output: String.

UI: If response != input, underline differences in Red.

üí¨ Phase 3: Context & Immersion

Goal: Deep practice handling conversation and culture.

9. Conversation Mode (Sliding Window)

Action: Build a Chat Screen.

Token Strategy: When sending chat history to AI, use history.slice(-6).

Why: Only send the last 3 exchanges (User+AI). Sending the full 50-message history is extremely expensive and usually unnecessary for context.

10. Cultural Intelligence (Integrated)

Action: Parse the cult_warn field from the Main Prediction JSON (setup in Phase 0).

UI: If cult_warn is not null, display a small "‚ö†Ô∏è" icon on the chip.

Interaction: Tap icon -> Show Alert: "In this context, 'tu' is rude. Use 'usted'."

Note: This requires no extra API calls; it's piggybacked on the prediction.

üéôÔ∏è Phase 4: Audio Lab (Native APIs)

Goal: Speaking/Listening using free on-device tools.

11. TTS & Recording

TTS: Use expo-speech to read the AI's predicted sentence.

Recording: Use expo-av to capture user voice.

12. Visual Waveform (The "Fake" Visualizer)

Problem: Real-time waveform analysis in JS is laggy.

Solution: Use expo-av metering data.

While recording, grab metering (volume level) every 100ms.

Pass this value to a react-native-reanimated Bar height.

Result: A bar graph that jumps with the user's voice volume.

üìä Phase 5: Learning Analytics (Local Aggregation)

Goal: Visual feedback using locally stored data (Privacy + Cost efficient).

13. Local Data Aggregation

Action: Write SQL queries in db.ts to summarize data before visualizing.

Heatmap: SELECT date, count(*) FROM user_stats GROUP BY date

Skills: SELECT type, avg(score) FROM user_stats GROUP BY type

14. Dashboard UI

Action: Install react-native-gifted-charts.

Implementation:

Heatmap: Map SQL results to a grid of colored squares.

Radar: Map "Skills" query to a Spider Web chart (Vocab, Grammar, etc.).

15. AI Insights (Compressed)

Action: Generate a text summary for the AI.

Process:

Don't send the raw SQL rows.

Do send a string: "User Activity: High. Weakness: Grammar (score 40%)."

Prompt: "Based on this summary, give 1 sentence of advice."

Display: Show the result at the top of the dashboard.

16. Export Report

Action: Create a button "Export Progress".

Process:

Query all tables.

Convert JSON to CSV string.

Use expo-file-system to write report.csv.

Use expo-sharing to open the share sheet.

üìâ Cost Impact Summary

If you follow this exact plan:

Ghost Text/Trigger Logic: Reduces API calls by ~50% (Ignoring partial words).

SQLite Caching: Reduces API calls by ~40% (Recurring phrases are free).

Minified Prompts: Reduces cost per call by ~30%.

Local Analytics: Reduces Analytics cost by ~95%.